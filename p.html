<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>Pitch to C4 Converter</title>
  <style>
    body { font-family: system-ui, sans-serif; margin: 2rem; }
    button, input { font-size: 1rem; }
    .log { margin-top: 1rem; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h1>音声をC4へピッチ変換してダウンロード</h1>
  <input id="file" type="file" accept="audio/*" />
  <button id="convert" disabled>変換してダウンロード</button>
  <div class="log" id="log"></div>

<script>
const C4 = 261.6255653006; // Hz
const logEl = document.getElementById('log');
const fileEl = document.getElementById('file');
const convertBtn = document.getElementById('convert');

let audioBuffer = null;

function log(msg) {
  logEl.textContent += msg + '\n';
}

// 簡易オートコリレーションで基本周波数推定（モノラル化＆先頭数秒）
function estimateFundamentalFreq(buffer) {
  const sampleRate = buffer.sampleRate;
  const channelData = buffer.numberOfChannels > 1
    ? mixToMono(buffer)
    : buffer.getChannelData(0);

  const secondsToAnalyze = Math.min(3, buffer.duration);
  const size = Math.min(channelData.length, Math.floor(secondsToAnalyze * sampleRate));

  // 窓抜き＆正規化
  const data = channelData.slice(0, size);
  // 直流成分除去
  const mean = data.reduce((a, b) => a + b, 0) / data.length;
  for (let i = 0; i < data.length; i++) data[i] -= mean;

  // オートコリレーション
  const maxLag = Math.floor(sampleRate / 50);   // 下限50Hz
  const minLag = Math.floor(sampleRate / 1000); // 上限1000Hz
  let bestLag = -1;
  let bestCorr = 0;

  for (let lag = minLag; lag <= maxLag; lag++) {
    let sum = 0;
    for (let i = 0; i < data.length - lag; i++) {
      sum += data[i] * data[i + lag];
    }
    const corr = sum / (data.length - lag);
    if (corr > bestCorr) {
      bestCorr = corr;
      bestLag = lag;
    }
  }

  if (bestLag <= 0) return null;
  const freq = sampleRate / bestLag;
  return freq;
}

function mixToMono(buffer) {
  const len = buffer.length;
  const ch = buffer.numberOfChannels;
  const out = new Float32Array(len);
  for (let c = 0; c < ch; c++) {
    const d = buffer.getChannelData(c);
    for (let i = 0; i < len; i++) out[i] += d[i];
  }
  for (let i = 0; i < len; i++) out[i] /= ch;
  return out;
}

// WAVエンコード（16bit PCM, interleaved）
function encodeWAVFromBuffer(buffer) {
  const numChannels = buffer.numberOfChannels;
  const sampleRate = buffer.sampleRate;
  const length = buffer.length;
  const bytesPerSample = 2;
  const blockAlign = numChannels * bytesPerSample;
  const dataSize = length * blockAlign;

  const headerSize = 44;
  const totalSize = headerSize + dataSize;
  const arrayBuffer = new ArrayBuffer(totalSize);
  const view = new DataView(arrayBuffer);

  // RIFF/WAVEヘッダ
  writeString(view, 0, 'RIFF');
  view.setUint32(4, totalSize - 8, true);
  writeString(view, 8, 'WAVE');
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // PCM
  view.setUint16(20, 1, true);  // format=1
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * blockAlign, true);
  view.setUint16(32, blockAlign, true);
  view.setUint16(34, 16, true); // bits per sample
  writeString(view, 36, 'data');
  view.setUint32(40, dataSize, true);

  // サンプル書き込み
  let offset = 44;
  const interleaved = interleave(buffer);
  for (let i = 0; i < interleaved.length; i++) {
    const s = Math.max(-1, Math.min(1, interleaved[i]));
    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    offset += 2;
  }

  return new Blob([view], { type: 'audio/wav' });
}

function writeString(view, offset, str) {
  for (let i = 0; i < str.length; i++) {
    view.setUint8(offset + i, str.charCodeAt(i));
  }
}

function interleave(buffer) {
  const numChannels = buffer.numberOfChannels;
  const length = buffer.length;
  const out = new Float32Array(length * numChannels);
  const channels = [];
  for (let c = 0; c < numChannels; c++) channels[c] = buffer.getChannelData(c);

  let index = 0;
  for (let i = 0; i < length; i++) {
    for (let c = 0; c < numChannels; c++) {
      out[index++] = channels[c][i];
    }
  }
  return out;
}

fileEl.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (!file) return;
  logEl.textContent = '';
  log(`読み込み中: ${file.name}`);

  const arrayBuffer = await file.arrayBuffer();
  const ctx = new (window.AudioContext || window.webkitAudioContext)();
  try {
    audioBuffer = await ctx.decodeAudioData(arrayBuffer);
    log(`サンプルレート: ${audioBuffer.sampleRate} Hz, チャンネル: ${audioBuffer.numberOfChannels}, 長さ: ${audioBuffer.duration.toFixed(2)} s`);
    convertBtn.disabled = false;
  } catch (err) {
    log(`デコード失敗: ${err}`);
    convertBtn.disabled = true;
  } finally {
    ctx.close();
  }
});

convertBtn.addEventListener('click', async () => {
  if (!audioBuffer) return;
  log('ピッチ解析中...');
  const f0 = estimateFundamentalFreq(audioBuffer);
  if (!f0 || !isFinite(f0)) {
    log('基本周波数の推定に失敗しました（無音や複雑な音源の可能性）。');
    return;
  }
  log(`推定基本周波数: ${f0.toFixed(2)} Hz`);

  const ratio = C4 / f0;
  log(`C4への変換比率 (playbackRate): ${ratio.toFixed(6)}`);

  // OfflineAudioContextでリサンプリング（時間は変わる）
  const length = Math.ceil(audioBuffer.length / ratio); // 再生速度が速いほど短くなる
  const offline = new OfflineAudioContext({
    numberOfChannels: audioBuffer.numberOfChannels,
    length,
    sampleRate: audioBuffer.sampleRate
  });

  const source = offline.createBufferSource();
  source.buffer = audioBuffer;
  source.playbackRate.value = ratio;
  source.connect(offline.destination);
  source.start(0);

  log('レンダリング中...');
  const rendered = await offline.startRendering();

  log('WAVエンコード中...');
  const wavBlob = encodeWAVFromBuffer(rendered);
  const url = URL.createObjectURL(wavBlob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'converted_to_C4.wav';
  document.body.appendChild(a);
  a.click();
  a.remove();
  URL.revokeObjectURL(url);
  log('ダウンロードを開始しました。');
});
</script>
</body>
</html>
