<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8" />
<title>Pure JS MIDI Player</title>
<style>
  body { font-family: system-ui, sans-serif; padding: 20px; background:black; color:white;}
  .log { white-space: pre-wrap; font-family: ui-monospace, monospace; background: #111; color: #ddd; padding: 10px; border-radius: 6px; }
  button { margin-right: 8px; }
</style>
</head>
<body>
  <h1>Pure JS MIDI Player (No libraries)</h1>
  <input type="file" id="midiFile" accept=".mid,.midi" />
  <button id="playBtn" disabled>Play</button>
  <button id="stopBtn" disabled>Stop</button>
<canvas style="display:none" id="pianoRoll" width="800" height="400"></canvas>

  <div class="log" id="log" style="display:none"></div>
<input type="file" id="sampleFile" accept=".wav,.mp3" />
<script>
let startTicks;
const roll = document.getElementById("pianoRoll");
const ctx = roll.getContext("2d");
let activeNotes = []; // {note, start, end}

function handleNoteOn(note, timeMs) {
  activeNotes.push({note, start: timeMs, end: null});
}
function handleNoteOff(note, timeMs) {
  const n = activeNotes.find(x => x.note === note && x.end === null);
  if (n) n.end = timeMs;
}
function drawRoll(nowMs) {
  ctx.clearRect(0, 0, roll.width, roll.height);

  const speed = 0.1; // px/ms
  const noteHeight = 6;

  activeNotes.forEach(n => {
    const startX = (n.start - nowMs) * speed + roll.width/2;
    const endX   = ((n.end ?? nowMs) - nowMs) * speed + roll.width/2;
    const w = endX - startX;
    const y = roll.height - (n.note * noteHeight % roll.height);

    ctx.fillStyle = "skyblue";
    ctx.fillRect(startX, y, w, noteHeight);
  });

  // 現在位置カーソル
  ctx.strokeStyle = "red";
  ctx.beginPath();
  ctx.moveTo(roll.width/2, 0);
  ctx.lineTo(roll.width/2, roll.height);
  ctx.stroke();
}

function animate() {
  const nowMs = performance.now() - startTicks;
  drawRoll(nowMs);
  requestAnimationFrame(animate);
}

    let audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    document.getElementById("sampleFile").addEventListener("change", async (e) => {
  const file = e.target.files[0];
  if (!file) return;

  const reader = new FileReader();
  reader.onload = async (event) => {
    const arrayBuffer = event.target.result;
    sampleBuffer = await audioCtx.decodeAudioData(arrayBuffer);
    console.log("Sample loaded:", file.name);
  };
  reader.readAsArrayBuffer(file);
});
// --------------------------
// Minimal MIDI parser (SMF)
// --------------------------
function parseMidi(arrayBuffer) {
  const data = new DataView(arrayBuffer);
  let offset = 0;

  function readUint32BE() {
    const v = data.getUint32(offset, false);
    offset += 4;
    return v;
  }
  function readUint16BE() {
    const v = data.getUint16(offset, false);
    offset += 2;
    return v;
  }
  function readBytes(n) {
    const bytes = [];
    for (let i = 0; i < n; i++) bytes.push(data.getUint8(offset++));
    return bytes;
  }
  function readStr(n) {
    return String.fromCharCode(...readBytes(n));
  }
  function readVarLen() {
    let value = 0;
    while (true) {
      const b = data.getUint8(offset++);
      value = (value << 7) | (b & 0x7F);
      if ((b & 0x80) === 0) break;
    }
    return value;
  }

  const headerId = readStr(4);
  if (headerId !== "MThd") throw new Error("Invalid MIDI header");
  const headerLength = readUint32BE(); // usually 6
  const formatType = readUint16BE();
  const trackCount = readUint16BE();
  const division = readUint16BE();
  // Consume any extra header bytes (rare)
  if (headerLength > 6) offset += (headerLength - 6);

  const tracks = [];
  for (let t = 0; t < trackCount; t++) {
    const trackId = readStr(4);
    if (trackId !== "MTrk") throw new Error("Invalid Track header");
    const trackLength = readUint32BE();
    const trackEnd = offset + trackLength;

    const events = [];
    let runningStatus = null;
    let absTicks = 0;

    while (offset < trackEnd) {
      const delta = readVarLen();
      absTicks += delta;

      let statusByte = data.getUint8(offset++);
      if (statusByte < 0x80) {
        // running status
        offset--;
        statusByte = runningStatus;
      } else {
        runningStatus = statusByte;
      }

      if (statusByte === 0xFF) {
        const metaType = data.getUint8(offset++);
        const length = readVarLen();
        const metaData = readBytes(length);
        events.push({ absTicks, type: "meta", metaType, data: metaData });
      } else if (statusByte === 0xF0 || statusByte === 0xF7) {
        const length = readVarLen();
        const sysExData = readBytes(length);
        events.push({ absTicks, type: "sysex", data: sysExData });
      } else {
        const evtType = statusByte >> 4;
        const channel = statusByte & 0x0F;
        const needsTwo = !(evtType === 0xC || evtType === 0xD);
        const p1 = data.getUint8(offset++);
        const p2 = needsTwo ? data.getUint8(offset++) : null;
        events.push({ absTicks, type: "midi", evtType, channel, p1, p2 });
      }
    }
    tracks.push(events);
  }

  return { header: { formatType, trackCount, division }, tracks };
}

// -------------------------------------
// Simple synth and scheduler (WebAudio)
// -------------------------------------
function midiNoteToPlaybackRate(note, baseNote = 60) {
  return Math.pow(2, (note - baseNote) / 12);
}

// ユーティリティ: Wavetable作成
function createWavetable(ctx, table) {
  const real = new Float32Array(table.length);
  const imag = new Float32Array(table.length);
  for (let i = 0; i < table.length; i++) {
    real[i] = table[i];
  }
  return ctx.createPeriodicWave(real, imag);
}

// ADSR エンベロープをスケジュール
function scheduleADSR(param, t, dur, env) {
  const { a=0.01, d=0.1, s=0.7, r=0.2 } = env;
  param.setValueAtTime(0, t);
  param.linearRampToValueAtTime(1, t + a);
  param.linearRampToValueAtTime(s, t + a + d);
  const releaseStart = t + dur;
  param.setValueAtTime(s, releaseStart);
  param.linearRampToValueAtTime(0, releaseStart + r);
  return { stopAt: releaseStart + r };
}

class MidiSynth {
  constructor(audioCtx) {
    this.audioCtx = audioCtx;
    this.master = audioCtx.createGain();
    this.master.gain.value = 0.3;
    this.master.connect(audioCtx.destination);
    
    this.instruments = new Map(); // 音源名 -> factory関数
    this.channelInstrumentFactories = new Array(16).fill(null); // チャンネル -> factory
    this.channelInstrumentOpts = new Array(16).fill(null); // チャンネル -> opts
    this.activeNotes = new Map(); // key: channel-note -> {voice, stopTime}
    
    // デフォルト音源を登録
    this.registerDefaultInstruments();
  }
  
  // 音源を登録
  registerInstrument(name, factory) {
    this.instruments.set(name, factory);
  }
  
  // チャンネルに音源を割り当て
  setChannelInstrument(channel, instrumentName, opts = {}) {
    if (channel < 0 || channel >= 16) return;
    
    const factory = this.instruments.get(instrumentName);
    if (!factory) {
      console.warn(`Instrument "${instrumentName}" not found`);
      return;
    }
    
    this.channelInstrumentFactories[channel] = factory;
    this.channelInstrumentOpts[channel] = opts;
  }
  
  midiNoteToFreq(n) {
    return 440 * Math.pow(2, (n - 69) / 12);
  }
  
  noteOn(channel, note, velocity, when) {
    const factory = this.channelInstrumentFactories[channel];
    if (!factory) {
      console.warn(`No instrument on channel ${channel}`);
      return;
    }
    
    const freq = this.midiNoteToFreq(note);
    const vel = velocity / 127;
    const key = `${channel}-${note}`;
    
    // 既に同じノートが鳴っていたら停止
    if (this.activeNotes.has(key)) {
      this.noteOff(channel, note, when);
    }
    
    // 新しい音源インスタンスを作成
    const opts = this.channelInstrumentOpts[channel] || {};
    const voice = factory(this.audioCtx, opts);
    
    // ノートを開始 (dur=999で長めに設定、noteOffで実際の長さを決定)
    voice.start(when, freq, 999, vel);
    
    this.activeNotes.set(key, { voice, startTime: when, freq, vel });
  }
  
  noteOff(channel, note, when) {
    const key = `${channel}-${note}`;
    const info = this.activeNotes.get(key);
    if (!info) return;
    
    const { voice, startTime } = info;
    const actualDuration = when - startTime;
    
    // リリースフェーズに入る（各音源のstop実装に依存）
    if (voice && voice.stop) {
      voice.stop(when, actualDuration);
    }
    
    this.activeNotes.delete(key);
  }
  
  programChange(channel, program, when) {
    // プログラムチェンジで音源を切り替え (オプション)
  }
  
  controlChange(channel, controller, value, when) {
    // CC実装可能
  }
  
  pitchBend(channel, value14, when) {
    // ピッチベンド実装可能
  }
  
  // デフォルト音源を登録
  registerDefaultInstruments() {
    // FDS風音源
    this.registerInstrument('fds', (ctx, opts={}) => {
      const { gain=0.8, pan=0, table=null, modDepth=0.2, modRate=5 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan }); 
      out.connect(p).connect(this.master);
      
      const defaultTable = Array.from({length:32}, (_,i)=> Math.sin(2*Math.PI*i/32));
      const wav = createWavetable(ctx, table ?? defaultTable);
      
      let osc, lfo, g, lfoGain;
      
      return {
        start(t, freq, dur, vel=1) {
          osc = ctx.createOscillator();
          osc.setPeriodicWave(wav);
          osc.frequency.setValueAtTime(freq, t);
          
          lfo = ctx.createOscillator();
          lfoGain = ctx.createGain();
          lfo.frequency.setValueAtTime(modRate, t);
          lfoGain.gain.setValueAtTime(freq * modDepth, t);
          lfo.connect(lfoGain).connect(osc.frequency);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(0, t);
          g.gain.linearRampToValueAtTime(vel, t + 0.01);
          g.connect(out);
          
          osc.connect(g);
          lfo.start(t);
          osc.start(t);
        },
        stop(t, actualDur) {
          if (!g) return;
          g.gain.cancelScheduledValues(t);
          g.gain.setValueAtTime(g.gain.value, t);
          g.gain.linearRampToValueAtTime(0, t + 0.12);
          const stopAt = t + 0.15;
          if (lfo) lfo.stop(stopAt);
          if (osc) osc.stop(stopAt);
        }
      };
    });
    
    // サウ波シンセ
    this.registerInstrument('sawtooth', (ctx, opts={}) => {
      const { gain=0.4, pan=0, cutoff=2000 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(this.master);
      
      let osc, filter, g;
      
      return {
        start(t, freq, dur, vel=1) {
          osc = ctx.createOscillator();
          osc.type = 'sawtooth';
          osc.frequency.setValueAtTime(freq, t);
          
          filter = ctx.createBiquadFilter();
          filter.type = 'lowpass';
          filter.frequency.setValueAtTime(cutoff, t);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(0, t);
          g.gain.linearRampToValueAtTime(vel, t + 0.01);
          g.connect(out);
          
          osc.connect(filter).connect(g);
          osc.start(t);
        },
        stop(t, actualDur) {
          if (!g) return;
          g.gain.cancelScheduledValues(t);
          g.gain.setValueAtTime(g.gain.value, t);
          g.gain.linearRampToValueAtTime(0, t + 0.2);
          if (osc) osc.stop(t + 0.25);
        }
      };
    });
    
    // パルス波ベース
    this.registerInstrument('pulse', (ctx, opts={}) => {
      const { gain=0.45, pan=0 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(this.master);
      
      let osc, g;
      
      return {
        start(t, freq, dur, vel=1) {
          osc = ctx.createOscillator();
          osc.type = 'square';
          osc.frequency.setValueAtTime(freq, t);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(0, t);
          g.gain.linearRampToValueAtTime(vel, t + 0.005);
          g.connect(out);
          
          osc.connect(g);
          osc.start(t);
        },
        stop(t, actualDur) {
          if (!g) return;
          g.gain.cancelScheduledValues(t);
          g.gain.setValueAtTime(g.gain.value, t);
          g.gain.linearRampToValueAtTime(0, t + 0.15);
          if (osc) osc.stop(t + 0.2);
        }
      };
    });
    this.registerInstrument('ym2612', (ctx, opts = {}) => {
  const {
    gain = 0.4,
    pan = 0,
    modIndex = 2.0,   // FM深さ
    modRatio = 2.0,   // モジュレータ周波数比
    attack = 0.01,
    decay = 0.1,
    sustain = 0.6,
    release = 0.2
  } = opts;

  const out = ctx.createGain();
  out.gain.value = gain;

  const p = new StereoPannerNode(ctx, { pan });
  out.connect(p).connect(this.master);

  let carrier, mod, amp;

  return {
    start(t, freq, dur, vel = 1) {
      // --- モジュレータ ---
      mod = ctx.createOscillator();
      mod.type = 'sine';
      mod.frequency.setValueAtTime(freq * modRatio, t);

      const modGain = ctx.createGain();
      modGain.gain.setValueAtTime(freq * modIndex, t);

      mod.connect(modGain);

      // --- キャリア ---
      carrier = ctx.createOscillator();
      carrier.type = 'sine';
      carrier.frequency.setValueAtTime(freq, t);

      modGain.connect(carrier.frequency);

      // --- アンプ ---
      amp = ctx.createGain();
      amp.gain.setValueAtTime(0, t);
      amp.gain.linearRampToValueAtTime(vel, t + attack);
      amp.gain.linearRampToValueAtTime(
        vel * sustain,
        t + attack + decay
      );

      carrier.connect(amp);
      amp.connect(out);

      mod.start(t);
      carrier.start(t);

      if (dur) {
        this.stop(t + dur, dur);
      }
    },

    stop(t) {
      if (!amp) return;

      amp.gain.cancelAndHoldAtTime(t);
      amp.gain.linearRampToValueAtTime(0, t + release);

      carrier.stop(t + release + 0.05);
      mod.stop(t + release + 0.05);
    }
  };
});

    // ノイズパーカッション
    this.registerInstrument('noise', (ctx, opts={}) => {
      const { gain=2.0, pan=0 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(this.master);
      
      const createNoiseBuffer = () => {
        const bufferSize = ctx.sampleRate * 0.5;
        const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
        const data = buffer.getChannelData(0);
        for (let i = 0; i < bufferSize; i++) {
          data[i] = Math.random() * 2 - 1;
        }
        return buffer;
      };
      const noiseBuffer = createNoiseBuffer();
      
      let noise, filter, g;
      
      return {
        start(t, freq, dur, vel=1) {
          noise = ctx.createBufferSource();
          noise.buffer = noiseBuffer;
          
          filter = ctx.createBiquadFilter();
          filter.type = 'bandpass';
          filter.frequency.setValueAtTime(freq * 8, t);
          filter.Q.setValueAtTime(5, t);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(vel, t);
          g.gain.exponentialRampToValueAtTime(0.001, t + 0.08);
          g.connect(out);
          
          noise.connect(filter).connect(g);
          noise.start(t);
          noise.stop(t + 0.1);
        },
        stop(t, actualDur) {
          // ノイズは自動停止するのでstopは不要
        }
      };
    });
  }
}
//
// // チャンネルに音源を割り当て
// synth.setChannelInstrument(0, 'fds', { modDepth: 0.03, modRate: 6 });
// synth.setChannelInstrument(1, 'sawtooth', { cutoff: 1500 });
// synth.setChannelInstrument(2, 'pulse');
// synth.setChannelInstrument(9, 'noise');
//
// // ノートオン/オフ
// synth.noteOn(0, 60, 100, audioCtx.currentTime);
// synth.noteOff(0, 60, audioCtx.currentTime + 1);
//
// // カスタム音源の登録も可能
// synth.registerInstrument('custom', (ctx, opts={}) => {
//   return {
//     start(t, freq, dur, vel) { /* ... */ },
//     stop(t, dur) { /* ... */ }
//   };
// });
let playheadTicks = 0;
let lastCtxTime = 0;




// Convert ticks to seconds with tempo map
function buildTempoMap(tracks, division) {
  // division: ticks per quarter (if positive). SMPTE not supported in this minimal player.
  const tempoEvents = [];
  for (const trk of tracks) {
    for (const ev of trk) {
      if (ev.type === "meta" && ev.metaType === 0x51 && ev.data.length === 3) {
        const mpb = (ev.data[0] << 16) | (ev.data[1] << 8) | ev.data[2]; // microseconds per quarter
        tempoEvents.push({ absTicks: ev.absTicks, microsecPerQuarter: mpb });
      }
    }
  }
  tempoEvents.sort((a, b) => a.absTicks - b.absTicks);
  // Default tempo: 500000 microsec/quarter (120 BPM)
  const segments = [];
  let lastTick = 0;
  let currentMicro = 500000;
  let currentSec = 0;

  segments.push({ startTick: 0, startSec: 0, micro: currentMicro });
  for (const t of tempoEvents) {
    const deltaTicks = t.absTicks - lastTick;
    const secDelta = (deltaTicks * currentMicro) / (division * 1_000_000);
    currentSec += secDelta;
    segments.push({ startTick: t.absTicks, startSec: currentSec, micro: t.microsecPerQuarter });
    lastTick = t.absTicks;
    currentMicro = t.microsecPerQuarter;
  }
  return segments;
}

function ticksToSeconds(absTicks, segments, division) {
  // Find last segment where startTick <= absTicks
  let seg = segments[0];
  for (let i = 1; i < segments.length; i++) {
    if (segments[i].startTick <= absTicks) seg = segments[i];
    else break;
  }
  const deltaTicks = absTicks - seg.startTick;
  const secDelta = (deltaTicks * seg.micro) / (division * 1_000_000);
  return seg.startSec + secDelta;
}

// Flatten and sort all events
function collectAllEvents(tracks) {
  const all = [];
  for (const trk of tracks) for (const ev of trk) all.push(ev);
  all.sort((a, b) => a.absTicks - b.absTicks);
  return all;
}

// --------------------------
// UI / Playback integration
// --------------------------
const fileInput = document.getElementById('midiFile');
const playBtn = document.getElementById('playBtn');
const stopBtn = document.getElementById('stopBtn');
const logEl = document.getElementById('log');

let parsed = null;

let synth = null;
let startAtCtxTime = 0;
let scheduled = []; // keep for stop

function log(msg) { logEl.textContent += msg + "\n"; }

fileInput.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (!file) return;
  const buf = await file.arrayBuffer();
  try {
    parsed = parseMidi(buf);
    log(`Loaded: ${file.name}`);
    log(`Format: ${parsed.header.formatType}, Tracks: ${parsed.header.trackCount}, Division: ${parsed.header.division}`);
    playBtn.disabled = false;
    stopBtn.disabled = true;
  } catch (err) {
    log(`Error: ${err.message}`);
  }
});

playBtn.addEventListener('click', () => {
  if (!parsed) return;
  if (audioCtx.state === "suspended") {
    audioCtx.resume();
  }
  synth = new MidiSynth(audioCtx);
synth.setChannelInstrument(0, 'ym2612');
synth.setChannelInstrument(1, 'fds', { modDepth: 0.03, modRate: 6 });
 synth.setChannelInstrument(2, 'sawtooth', { cutoff: 1500 });
 synth.setChannelInstrument(3, 'ym2612');
synth.setChannelInstrument(4, 'sawtooth', { cutoff: 1500 });
synth.setChannelInstrument(5, 'pulse');
synth.setChannelInstrument(6, 'sawtooth', { cutoff: 1500 });
synth.setChannelInstrument(7, 'pulse');
synth.setChannelInstrument(8, 'ym2612');
 synth.setChannelInstrument(9, 'noise');
synth.setChannelInstrument(10, 'noise');
 synth.setChannelInstrument(11, 'pulse');
synth.setChannelInstrument(12, 'sawtooth', { cutoff: 1500 });
 synth.setChannelInstrument(13, 'pulse');
synth.setChannelInstrument(14, 'pulse');
synth.setChannelInstrument(15, 'pulse');
synth.setChannelInstrument(16, 'pulse');

  const { division } = parsed.header;
  if ((division & 0x8000) !== 0) {
    log("SMPTE division is not supported.");
    return;
  }

  const tempoMap = buildTempoMap(parsed.tracks, division);
  const all = collectAllEvents(parsed.tracks);

  startTicks = performance.now(); // msベースのリアルタイム基準
  let idx = 0;
  requestAnimationFrame(animate);
  function step() {
    const lookAhead = 0.1; // 100ms
    const now = performance.now();
    const audioNow = audioCtx.currentTime;
    while (idx < all.length) {
      const ev = all[idx];
        
      const evTimeMs = ticksToSeconds(ev.absTicks, tempoMap, division) * 1000;
      const deltaMs = evTimeMs - (now - startTicks);
      if (deltaMs <= lookAhead * 1000) {
    const scheduleTime = Math.abs(audioNow + deltaMs / 1000);
    
        if (ev.type === "midi") {
          const ch = ev.channel;
          switch (ev.evtType) {
            case 0x9: { // note on
              const note = ev.p1;
              const vel = ev.p2 || 0;
              if (vel > 0){ synth.noteOn(ch, note, vel,scheduleTime); handleNoteOn(note,evTimeMs);
              }else {synth.noteOff(ch, note, scheduleTime);handleNoteOff(note,evTimeMs); }
              break;
            }
            case 0x8: { // note off
const note = ev.p1;
                handleNoteOff(note,evTimeMs); 
              synth.noteOff(ch, ev.p1, scheduleTime);
              break;
            }
            case 0xC: {
              synth.programChange(ch, ev.p1, scheduleTime);
              break;
            }
            case 0xB: {
              synth.controlChange(ch, ev.p1, ev.p2 || 0, scheduleTime);
              break;
            }
            case 0xE: {
              const lsb = ev.p1 || 0, msb = ev.p2 || 0;
              const v14 = (msb << 7) | lsb;
              synth.pitchBend(ch, v14, scheduleTime);
              break;
            }
          }
        }
        idx++;
      } else {
        break; // まだ未来のイベントなので待つ
      }
    }
    if (idx < all.length) {
      setTimeout(step, 10);
    } else {
      log("Finished.");
      playBtn.disabled = false;
      stopBtn.disabled = true;
    }
  }

  playBtn.disabled = true;
  stopBtn.disabled = false;
  log("Playing...");
  requestAnimationFrame(step);
});

stopBtn.addEventListener('click', () => {
  // Stop scheduled callbacks
  for (const id of scheduled) clearTimeout(id);
  scheduled = [];
  // Kill active notes
  if (synth) {
    const now = audioCtx ? audioCtx.currentTime : 0;
    for (const key of synth.activeNotes.keys()) {
      const [ch, note] = key.split('-').map(Number);
      synth.noteOff(ch, note, now);
    }
  }
  playBtn.disabled = false;
  stopBtn.disabled = true;
  log("Stopped.");
});
</script>
</body>
</html>
