<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8" />
<title>Pure JS MIDI Player</title>
<style>
  body { font-family: system-ui, sans-serif; padding: 20px; background:black; color:white;}
  .log { white-space: pre-wrap; font-family: ui-monospace, monospace; background: #111; color: #ddd; padding: 10px; border-radius: 6px; }
  button { margin-right: 8px; }
</style>
</head>
<body>
  <h1>Pure JS MIDI Player (No libraries)</h1>
  <input type="file" id="midiFile" accept=".mid,.midi" />
  <button id="playBtn" disabled>Play</button>
  <button id="stopBtn" disabled>Stop</button>
<div id="visualizer" style="display:grid; grid-template-columns:repeat(4,1fr); gap:0px; margin:20px 0;">
</div>
  <div class="log" id="log" style="display:none"></div>
<input type="file" id="sampleFile" accept=".wav,.mp3" />
<script>
let startTicks;

let activeNotes = []; // {note, start, end}

function handleNoteOn(note, timeMs) {
  activeNotes.push({note, start: timeMs, end: null});
}
function handleNoteOff(note, timeMs) {
  const n = activeNotes.find(x => x.note === note && x.end === null);
  if (n) n.end = timeMs;
}


    let audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    document.getElementById("sampleFile").addEventListener("change", async (e) => {
  const file = e.target.files[0];
  if (!file) return;

  const reader = new FileReader();
  reader.onload = async (event) => {
    const arrayBuffer = event.target.result;
    sampleBuffer = await audioCtx.decodeAudioData(arrayBuffer);
    console.log("Sample loaded:", file.name);
  };
  reader.readAsArrayBuffer(file);
});
// --------------------------
// Minimal MIDI parser (SMF)
// --------------------------
function parseMidi(arrayBuffer) {
  const data = new DataView(arrayBuffer);
  let offset = 0;

  function readUint32BE() {
    const v = data.getUint32(offset, false);
    offset += 4;
    return v;
  }
  function readUint16BE() {
    const v = data.getUint16(offset, false);
    offset += 2;
    return v;
  }
  function readBytes(n) {
    const bytes = [];
    for (let i = 0; i < n; i++) bytes.push(data.getUint8(offset++));
    return bytes;
  }
  function readStr(n) {
    return String.fromCharCode(...readBytes(n));
  }
  function readVarLen() {
    let value = 0;
    while (true) {
      const b = data.getUint8(offset++);
      value = (value << 7) | (b & 0x7F);
      if ((b & 0x80) === 0) break;
    }
    return value;
  }

  const headerId = readStr(4);
  if (headerId !== "MThd") throw new Error("Invalid MIDI header");
  const headerLength = readUint32BE(); // usually 6
  const formatType = readUint16BE();
  const trackCount = readUint16BE();
  const division = readUint16BE();
  // Consume any extra header bytes (rare)
  if (headerLength > 6) offset += (headerLength - 6);

  const tracks = [];
  for (let t = 0; t < trackCount; t++) {
    const trackId = readStr(4);
    if (trackId !== "MTrk") throw new Error("Invalid Track header");
    const trackLength = readUint32BE();
    const trackEnd = offset + trackLength;

    const events = [];
    let runningStatus = null;
    let absTicks = 0;

    while (offset < trackEnd) {
      const delta = readVarLen();
      absTicks += delta;

      let statusByte = data.getUint8(offset++);
      if (statusByte < 0x80) {
        // running status
        offset--;
        statusByte = runningStatus;
      } else {
        runningStatus = statusByte;
      }

      if (statusByte === 0xFF) {
        const metaType = data.getUint8(offset++);
        const length = readVarLen();
        const metaData = readBytes(length);
        events.push({ absTicks, type: "meta", metaType, data: metaData });
      } else if (statusByte === 0xF0 || statusByte === 0xF7) {
        const length = readVarLen();
        const sysExData = readBytes(length);
        events.push({ absTicks, type: "sysex", data: sysExData });
      } else {
        const evtType = statusByte >> 4;
        const channel = statusByte & 0x0F;
        const needsTwo = !(evtType === 0xC || evtType === 0xD);
        const p1 = data.getUint8(offset++);
        const p2 = needsTwo ? data.getUint8(offset++) : null;
        events.push({ absTicks, type: "midi", evtType, channel, p1, p2 });
      }
    }
    tracks.push(events);
  }

  return { header: { formatType, trackCount, division }, tracks };
}

// -------------------------------------
// Simple synth and scheduler (WebAudio)
// -------------------------------------
function midiNoteToPlaybackRate(note, baseNote = 60) {
  return Math.pow(2, (note - baseNote) / 12);
}

// ユーティリティ: Wavetable作成
function createWavetable(ctx, table) {
  const real = new Float32Array(table.length);
  const imag = new Float32Array(table.length);
  for (let i = 0; i < table.length; i++) {
    real[i] = table[i];
  }
  return ctx.createPeriodicWave(real, imag);
}

// ADSR エンベロープをスケジュール
function scheduleADSR(param, t, dur, env) {
  const { a=0.01, d=0.1, s=0.7, r=0.2 } = env;
  param.setValueAtTime(0, t);
  param.linearRampToValueAtTime(1, t + a);
  param.linearRampToValueAtTime(s, t + a + d);
  const releaseStart = t + dur;
  param.setValueAtTime(s, releaseStart);
  param.linearRampToValueAtTime(0, releaseStart + r);
  return { stopAt: releaseStart + r };
}
// MidiSynthクラス全体を置き換え
class MidiSynth {
  constructor(audioCtx) {
    this.audioCtx = audioCtx;
    this.master = audioCtx.createGain();
    this.master.gain.value = 0.3;
    this.master.connect(audioCtx.destination);
    
    // === 追加: チャンネルごとのAnalyserノード ===
    this.channelAnalysers = [];
    this.channelGains = [];
    for (let i = 0; i < 16; i++) {
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const gain = audioCtx.createGain();
      gain.gain.value = 1.0;
      gain.connect(analyser);
      analyser.connect(this.master);
      this.channelAnalysers.push(analyser);
      this.channelGains.push(gain);
    }
    
    this.instruments = new Map();
    this.channelInstrumentFactories = new Array(16).fill(null);
    this.channelInstrumentOpts = new Array(16).fill(null);
    this.activeNotes = new Map();
    
    this.registerDefaultInstruments();
  }
  
  // 音源を登録
  registerInstrument(name, factory) {
    this.instruments.set(name, factory);
  }
  
  // チャンネルに音源を割り当て
  setChannelInstrument(channel, instrumentName, opts = {}) {
    if (channel < 0 || channel >= 16) return;
    
    const factory = this.instruments.get(instrumentName);
    if (!factory) {
      console.warn(`Instrument "${instrumentName}" not found`);
      return;
    }
    
    this.channelInstrumentFactories[channel] = factory;
    this.channelInstrumentOpts[channel] = opts;
  }
  
  midiNoteToFreq(n) {
    return 440 * Math.pow(2, (n - 69) / 12);
  }
  
  noteOn(channel, note, velocity, when) {
    const factory = this.channelInstrumentFactories[channel];
    if (!factory) {
      console.warn(`No instrument on channel ${channel}`);
      return;
    }
    
    const freq = this.midiNoteToFreq(note);
    const vel = velocity / 127;
    const key = `${channel}-${note}`;
    
    if (this.activeNotes.has(key)) {
      this.noteOff(channel, note, when);
    }
    
    const opts = this.channelInstrumentOpts[channel] || {};
    // === 修正: チャンネル番号とゲインを渡す ===
    const voice = factory(this.audioCtx, opts, channel, this.channelGains[channel]);
    
    voice.start(when, freq, 999, vel);
    
    this.activeNotes.set(key, { voice, startTime: when, freq, vel });
  }
  
  noteOff(channel, note, when) {
    const key = `${channel}-${note}`;
    const info = this.activeNotes.get(key);
    if (!info) return;
    
    const { voice, startTime } = info;
    const actualDuration = when - startTime;
    
    if (voice && voice.stop) {
      voice.stop(when, actualDuration);
    }
    
    this.activeNotes.delete(key);
  }
  
  programChange(channel, program, when) {
    // プログラムチェンジで音源を切り替え (オプション)
  }
  
  controlChange(channel, controller, value, when) {
    // CC実装可能
  }
  
  pitchBend(channel, value14, when) {
    // ピッチベンド実装可能
  }
  
  // デフォルト音源を登録
  registerDefaultInstruments() {
    const masterRef = this.master; // thisの参照を保持
    
    // FDS風音源
    this.registerInstrument('fds', (ctx, opts={}, channel=0, channelGain=null) => {
      const { gain=0.8, pan=0, table=null, modDepth=0.2, modRate=5 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan }); 
      out.connect(p).connect(channelGain || masterRef);
      
      const defaultTable = Array.from({length:32}, (_,i)=> Math.sin(2*Math.PI*i/32));
      const wav = createWavetable(ctx, table ?? defaultTable);
      
      let osc, lfo, g, lfoGain;
      
      return {
        start(t, freq, dur, vel=1) {
          osc = ctx.createOscillator();
          osc.setPeriodicWave(wav);
          osc.frequency.setValueAtTime(freq, t);
          
          lfo = ctx.createOscillator();
          lfoGain = ctx.createGain();
          lfo.frequency.setValueAtTime(modRate, t);
          lfoGain.gain.setValueAtTime(freq * modDepth, t);
          lfo.connect(lfoGain).connect(osc.frequency);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(0, t);
          g.gain.linearRampToValueAtTime(vel, t + 0.01);
          g.connect(out);
          
          osc.connect(g);
          lfo.start(t);
          osc.start(t);
        },
        stop(t, actualDur) {
          if (!g) return;
          g.gain.cancelScheduledValues(t);
          g.gain.setValueAtTime(g.gain.value, t);
          g.gain.linearRampToValueAtTime(0, t + 0.12);
          const stopAt = t + 0.15;
          if (lfo) lfo.stop(stopAt);
          if (osc) osc.stop(stopAt);
        }
      };
    });
    
    // サウ波シンセ
    this.registerInstrument('sawtooth', (ctx, opts={}, channel=0, channelGain=null) => {
      const { gain=0.4, pan=0, cutoff=2000 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(channelGain || masterRef);
      
      let osc, filter, g;
      
      return {
        start(t, freq, dur, vel=1) {
          osc = ctx.createOscillator();
          osc.type = 'sawtooth';
          osc.frequency.setValueAtTime(freq, t);
          
          filter = ctx.createBiquadFilter();
          filter.type = 'lowpass';
          filter.frequency.setValueAtTime(cutoff, t);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(0, t);
          g.gain.linearRampToValueAtTime(vel, t + 0.01);
          g.connect(out);
          
          osc.connect(filter).connect(g);
          osc.start(t);
        },
        stop(t, actualDur) {
          if (!g) return;
          g.gain.cancelScheduledValues(t);
          g.gain.setValueAtTime(g.gain.value, t);
          g.gain.linearRampToValueAtTime(0, t + 0.2);
          if (osc) osc.stop(t + 0.25);
        }
      };
    });
    
    // パルス波ベース
    this.registerInstrument('pulse', (ctx, opts={}, channel=0, channelGain=null) => {
      const { gain=0.45, pan=0 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(channelGain || masterRef);
      
      let osc, g;
      
      return {
        start(t, freq, dur, vel=1) {
          osc = ctx.createOscillator();
          osc.type = 'square';
          osc.frequency.setValueAtTime(freq, t);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(0, t);
          g.gain.linearRampToValueAtTime(vel, t + 0.005);
          g.connect(out);
          
          osc.connect(g);
          osc.start(t);
        },
        stop(t, actualDur) {
          if (!g) return;
          g.gain.cancelScheduledValues(t);
          g.gain.setValueAtTime(g.gain.value, t);
          g.gain.linearRampToValueAtTime(0, t + 0.15);
          if (osc) osc.stop(t + 0.2);
        }
      };
    });
    
    this.registerInstrument('ym2612', (ctx, opts={}, channel=0, channelGain=null) => {
      const { gain=0.4, pan=0, modIndex=1.0, modRatio=2.0, attack=0.01, decay=0.1, sustain=0.6, release=0.2 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(channelGain || masterRef);
      
      let carrier, mod, amp;
      
      return {
        start(t, freq, dur, vel=1) {
          mod = ctx.createOscillator();
          mod.type = 'square';
          mod.frequency.setValueAtTime(freq * modRatio, t);
          
          const modGain = ctx.createGain();
          modGain.gain.setValueAtTime(freq * modIndex, t);
          mod.connect(modGain);
          
          carrier = ctx.createOscillator();
          carrier.type = 'sawtooth';
          carrier.frequency.setValueAtTime(freq, t);
          modGain.connect(carrier.frequency);
          
          amp = ctx.createGain();
          amp.gain.setValueAtTime(0, t);
          amp.gain.linearRampToValueAtTime(vel, t + attack);
          amp.gain.linearRampToValueAtTime(vel * sustain, t + attack + decay);
          
          carrier.connect(amp);
          amp.connect(out);
          
          mod.start(t);
          carrier.start(t);
        },
        stop(t) {
          if (!amp) return;
          amp.gain.cancelAndHoldAtTime(t);
          amp.gain.linearRampToValueAtTime(0, t + release);
          carrier.stop(t + release + 0.05);
          mod.stop(t + release + 0.05);
        }
      };
    });
    
    // ノイズパーカッション
    this.registerInstrument('noise', (ctx, opts={}, channel=0, channelGain=null) => {
      const { gain=19.0, pan=0 } = opts;
      const out = ctx.createGain(); out.gain.value = gain;
      const p = new StereoPannerNode(ctx, { pan });
      out.connect(p).connect(channelGain || masterRef);
      
      const createNoiseBuffer = () => {
        const bufferSize = ctx.sampleRate * 10;
        const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
        const data = buffer.getChannelData(0);
        for (let i = 0; i < bufferSize; i++) {
          data[i] = Math.random() * 2 - 1;
        }
        return buffer;
      };
      const noiseBuffer = createNoiseBuffer();
      
      let noise, filter, g;
      
      return {
        start(t, freq, dur, vel=1) {
          noise = ctx.createBufferSource();
          noise.buffer = noiseBuffer;
          
          filter = ctx.createBiquadFilter();
          filter.type = 'bandpass';
          filter.frequency.setValueAtTime(freq * 8, t);
          filter.Q.setValueAtTime(5, t);
          
          g = ctx.createGain();
          g.gain.setValueAtTime(vel, t);
          g.gain.exponentialRampToValueAtTime(0.001, t + 0.08);
          g.connect(out);
          
          noise.connect(filter).connect(g);
          noise.start(t);
          noise.stop(t + 0.1);
        },
        stop(t, actualDur) {}
      };
    });
this.registerInstrument('noise2', (ctx, opts={}, channel=0, channelGain=null) => {
  const { gain=2.6, pan=0 } = opts;

  const out = ctx.createGain();
  out.gain.value = gain;

  const p = new StereoPannerNode(ctx, { pan });
  out.connect(p).connect(channelGain || masterRef);

  // ===== 8bit風 LFSR ノイズ =====
  const createLFSRNoise = () => {
    const len = ctx.sampleRate * 2;
    const buf = ctx.createBuffer(1, len, ctx.sampleRate);
    const data = buf.getChannelData(0);

    let lfsr = 1;
    for (let i = 0; i < len; i++) {
      const bit = ((lfsr >> 0) ^ (lfsr >> 1)) & 1;
      lfsr = (lfsr >> 1) | (bit << 14);
      data[i] = (lfsr & 1) ? 0.8 : -0.8;
    }
    return buf;
  };

  const noiseBuffer = createLFSRNoise();

  let src;

  return {
    start(t, freq, dur, vel=1) {
      src = ctx.createBufferSource();
      src.buffer = noiseBuffer;
      src.loop = true;

      // ===== フィルタ =====
      const hp = ctx.createBiquadFilter();
      hp.type = 'highpass';
      hp.frequency.setValueAtTime(freq * 2, t);

      const lp = ctx.createBiquadFilter();
      lp.type = 'lowpass';
      lp.frequency.setValueAtTime(freq * 12, t);

      // ===== 歪み =====
      const shaper = ctx.createWaveShaper();
      const curve = new Float32Array(256);
      for (let i = 0; i < curve.length; i++) {
        const x = i * 2 / curve.length - 1;
        curve[i] = Math.tanh(x * 3);
      }
      shaper.curve = curve;

      // ===== エンベロープ =====
      const g = ctx.createGain();
      g.gain.setValueAtTime(0.001, t);
      g.gain.exponentialRampToValueAtTime(vel, t + 0.002); // パンチ
      g.gain.exponentialRampToValueAtTime(0.0001, t + 0.12);

      src
        .connect(hp)
        .connect(lp)
        .connect(shaper)
        .connect(g)
        .connect(out);

      src.start(t);
      src.stop(t + 0.15);
    },
    stop() {}
  };
});

  }
}

// === 可視化の初期化関数（元のコードの後ろに追加）===
function initVisualizer() {
  const container = document.getElementById('visualizer');
  container.innerHTML = '';
  
  for (let i = 0; i < 16; i++) {
    const wrapper = document.createElement('div');
    wrapper.style.cssText = 'background:#000; padding:0px;';
    
    const label = document.createElement('div');
    label.textContent = `Ch ${i}`;
    label.style.cssText = 'font-size:11px; color:#aaa; margin-bottom:0px;';
    
    const canvas = document.createElement('canvas');
    canvas.width = 200;
    canvas.height = 60;
    canvas.id = `canvas${i}`;
    canvas.style.cssText = 'border-radius:0px;width:100%; height:60px; display:block;';
    
    wrapper.appendChild(label);
    wrapper.appendChild(canvas);
    container.appendChild(wrapper);
  }
}

// === アニメーション関数（元のコードの後ろに追加）===
let animationId = null;
function animate() {
  if (!synth) return;
  
  for (let i = 0; i < 16; i++) {
    const canvas = document.getElementById(`canvas${i}`);
    if (!canvas) continue;
    
    const ctx = canvas.getContext('2d');
    const analyser = synth.channelAnalysers[i];
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    
    analyser.getByteTimeDomainData(dataArray);
    
    ctx.fillStyle = '#000';
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    
    ctx.lineWidth = 1.0;
    ctx.strokeStyle = `hsl(${i * 22.5}, 100%, 60%)`;
    ctx.beginPath();
    
    const sliceWidth = canvas.width / bufferLength;
    let x = 0;
    
    for (let j = 0; j < bufferLength; j++) {
      const v = dataArray[j] / 128.0;
      const y = v * canvas.height / 2;
      
      if (j === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
      
      x += sliceWidth;
    }
    
    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.stroke();
  }
  
  animationId = requestAnimationFrame(animate);
}

// // チャンネルに音源を割り当て
// synth.setChannelInstrument(0, 'fds', { modDepth: 0.03, modRate: 6 });
// synth.setChannelInstrument(1, 'sawtooth', { cutoff: 1500 });
// synth.setChannelInstrument(2, 'pulse');
// synth.setChannelInstrument(9, 'noise');
//
// // ノートオン/オフ
// synth.noteOn(0, 60, 100, audioCtx.currentTime);
// synth.noteOff(0, 60, audioCtx.currentTime + 1);
//
// // カスタム音源の登録も可能
// synth.registerInstrument('custom', (ctx, opts={}) => {
//   return {
//     start(t, freq, dur, vel) { /* ... */ },
//     stop(t, dur) { /* ... */ }
//   };
// });
let playheadTicks = 0;
let lastCtxTime = 0;




// Convert ticks to seconds with tempo map
function buildTempoMap(tracks, division) {
  // division: ticks per quarter (if positive). SMPTE not supported in this minimal player.
  const tempoEvents = [];
  for (const trk of tracks) {
    for (const ev of trk) {
      if (ev.type === "meta" && ev.metaType === 0x51 && ev.data.length === 3) {
        const mpb = (ev.data[0] << 16) | (ev.data[1] << 8) | ev.data[2]; // microseconds per quarter
        tempoEvents.push({ absTicks: ev.absTicks, microsecPerQuarter: mpb });
      }
    }
  }
  tempoEvents.sort((a, b) => a.absTicks - b.absTicks);
  // Default tempo: 500000 microsec/quarter (120 BPM)
  const segments = [];
  let lastTick = 0;
  let currentMicro = 500000;
  let currentSec = 0;

  segments.push({ startTick: 0, startSec: 0, micro: currentMicro });
  for (const t of tempoEvents) {
    const deltaTicks = t.absTicks - lastTick;
    const secDelta = (deltaTicks * currentMicro) / (division * 1_000_000);
    currentSec += secDelta;
    segments.push({ startTick: t.absTicks, startSec: currentSec, micro: t.microsecPerQuarter });
    lastTick = t.absTicks;
    currentMicro = t.microsecPerQuarter;
  }
  return segments;
}

function ticksToSeconds(absTicks, segments, division) {
  // Find last segment where startTick <= absTicks
  let seg = segments[0];
  for (let i = 1; i < segments.length; i++) {
    if (segments[i].startTick <= absTicks) seg = segments[i];
    else break;
  }
  const deltaTicks = absTicks - seg.startTick;
  const secDelta = (deltaTicks * seg.micro) / (division * 1_000_000);
  return seg.startSec + secDelta;
}

// Flatten and sort all events
function collectAllEvents(tracks) {
  const all = [];
  for (const trk of tracks) for (const ev of trk) all.push(ev);
  all.sort((a, b) => a.absTicks - b.absTicks);
  return all;
}

// --------------------------
// UI / Playback integration
// --------------------------
const fileInput = document.getElementById('midiFile');
const playBtn = document.getElementById('playBtn');
const stopBtn = document.getElementById('stopBtn');
const logEl = document.getElementById('log');

let parsed = null;

let synth = null;
let startAtCtxTime = 0;
let scheduled = []; // keep for stop

function log(msg) { logEl.textContent += msg + "\n"; }

fileInput.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (!file) return;
  const buf = await file.arrayBuffer();
  try {
    parsed = parseMidi(buf);
    log(`Loaded: ${file.name}`);
    log(`Format: ${parsed.header.formatType}, Tracks: ${parsed.header.trackCount}, Division: ${parsed.header.division}`);
    playBtn.disabled = false;
    stopBtn.disabled = true;
  } catch (err) {
    log(`Error: ${err.message}`);
  }
});

playBtn.addEventListener('click', () => {
  if (!parsed) return;
  if (audioCtx.state === "suspended") {
    audioCtx.resume();
  }
  initVisualizer();
  synth = new MidiSynth(audioCtx);
synth.setChannelInstrument(0, 'ym2612');
synth.setChannelInstrument(1, 'sawtooth', { modDepth: 0.03, modRate: 6 });
 synth.setChannelInstrument(2, 'sawtooth', { cutoff: 1500 });
 synth.setChannelInstrument(3, 'ym2612');
synth.setChannelInstrument(4, 'sawtooth', { cutoff: 1500 });
synth.setChannelInstrument(5, 'pulse');
synth.setChannelInstrument(6, 'sawtooth', { cutoff: 1500 });
synth.setChannelInstrument(7, 'sawtooth');
synth.setChannelInstrument(8, 'ym2612');
 synth.setChannelInstrument(9, 'noise2');
synth.setChannelInstrument(10, 'noise');
 synth.setChannelInstrument(11, 'pulse');
synth.setChannelInstrument(12, 'sawtooth', { cutoff: 1500 });
 synth.setChannelInstrument(13, 'pulse');
synth.setChannelInstrument(14, 'pulse');
synth.setChannelInstrument(15, 'pulse');
synth.setChannelInstrument(16, 'pulse');

  const { division } = parsed.header;
  if ((division & 0x8000) !== 0) {
    log("SMPTE division is not supported.");
    return;
  }

  const tempoMap = buildTempoMap(parsed.tracks, division);
  const all = collectAllEvents(parsed.tracks);

  startTicks = performance.now(); // msベースのリアルタイム基準
  let idx = 0;
  requestAnimationFrame(animate);
  function step() {
    const lookAhead = 0.1; // 100ms
    const now = performance.now();
    const audioNow = audioCtx.currentTime;
    while (idx < all.length) {
      const ev = all[idx];
        
      const evTimeMs = ticksToSeconds(ev.absTicks, tempoMap, division) * 1000;
      const deltaMs = evTimeMs - (now - startTicks);
      if (deltaMs <= lookAhead * 1000) {
    const scheduleTime = Math.abs(audioNow + deltaMs / 1000);
    
        if (ev.type === "midi") {
          const ch = ev.channel;
          switch (ev.evtType) {
            case 0x9: { // note on
              const note = ev.p1;
              const vel = ev.p2 || 0;
              if (vel > 0){ synth.noteOn(ch, note, vel,scheduleTime); handleNoteOn(note,evTimeMs);
              }else {synth.noteOff(ch, note, scheduleTime);handleNoteOff(note,evTimeMs); }
              break;
            }
            case 0x8: { // note off
const note = ev.p1;
                handleNoteOff(note,evTimeMs); 
              synth.noteOff(ch, ev.p1, scheduleTime);
              break;
            }
            case 0xC: {
              synth.programChange(ch, ev.p1, scheduleTime);
              break;
            }
            case 0xB: {
              synth.controlChange(ch, ev.p1, ev.p2 || 0, scheduleTime);
              break;
            }
            case 0xE: {
              const lsb = ev.p1 || 0, msb = ev.p2 || 0;
              const v14 = (msb << 7) | lsb;
              synth.pitchBend(ch, v14, scheduleTime);
              break;
            }
          }
        }
        idx++;
      } else {
        break; // まだ未来のイベントなので待つ
      }
    }
    if (idx < all.length) {
      setTimeout(step, 10);
    } else {
      log("Finished.");
      playBtn.disabled = false;
      stopBtn.disabled = true;
    }
  }

  playBtn.disabled = true;
  stopBtn.disabled = false;
  log("Playing...");
  animate();
  requestAnimationFrame(step);
});

stopBtn.addEventListener('click', () => {
  // Stop scheduled callbacks
  for (const id of scheduled) clearTimeout(id);
  scheduled = [];
  // Kill active notes
  if (synth) {
    const now = audioCtx ? audioCtx.currentTime : 0;
    for (const key of synth.activeNotes.keys()) {
      const [ch, note] = key.split('-').map(Number);
      synth.noteOff(ch, note, now);
    }
  }
  if (animationId) {
    cancelAnimationFrame(animationId);
    animationId = null;
  }
  playBtn.disabled = false;
  stopBtn.disabled = true;
  log("Stopped.");
});
</script>
</body>
</html>
